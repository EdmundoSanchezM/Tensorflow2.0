{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJr4nMgyb9oS"
   },
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
    "  Imagen cortesía de: https://www.kaggle.com/\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjlnjPnjWYFw"
   },
   "source": [
    "## Paso 1: Importar las dependencias necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yt0-hrch6rZw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1564588206066,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "_vv9AXUnZW78",
    "outputId": "a373495f-a620-462e-f10b-815bbeb81e42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2OiUS-kWkJU"
   },
   "source": [
    "## Paso 2: Pre procesado de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdfoFiEEXYj1"
   },
   "source": [
    "### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2705,
     "status": "ok",
     "timestamp": 1564588211057,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "-lCgz6UC8pKT",
    "outputId": "026f965e-3f9b-4fa0-f237-0dc0f8a09735"
   },
   "outputs": [],
   "source": [
    "#Cargar el dataset Fashion Mnist \n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYxeEHzDXdSs"
   },
   "source": [
    "### Normalizar las imágenes\n",
    "\n",
    "Se divide cada imagen en los conjunto de entrenamiento y  de testing entre el valor máximo de cada uno de los píxeles (255).\n",
    "\n",
    "De este modo, cada píxel se hallará en el rango [0, 1]. Al normalizar las imágenes, nos aseguramos que nuestro modelo de RNA entrenará más rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvWzsB3G9IU8"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lo--rpqo9ZtA"
   },
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBacLmGIX0Es"
   },
   "source": [
    "### Redimensionar el dataset\n",
    "\n",
    "Como vamos a utilizar una red neuronal totalmente conectada, vamos a redimensionar los subconjuntos de entrenamiento y testing a formato de vector en lugar de en formato de matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Tao7pom-grn"
   },
   "outputs": [],
   "source": [
    "#Como cada imagen tiene 28x28 píxeles, usamos la función reshape en todo el dataset de entrenamiento para convertirlo \n",
    "# en vectores de tamaño [-1 (todos los elementos), anchura * altura]\n",
    "X_train = X_train.reshape(-1, 28*28)#Pasar a array de vectores, uno por imagen (flattening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1564588234369,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "t9MbMrg9-kr_",
    "outputId": "a64ef84d-adbb-45f6-cc7b-e27aeab9c0ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_duQGtbCTTL"
   },
   "outputs": [],
   "source": [
    "#Redimensionamos el conjunto de testing del mismo modo\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5aDsaYSYmXD"
   },
   "source": [
    "## Paso 3: Construir la Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l30aZ6-GYtUP"
   },
   "source": [
    "### Definir el modelo\n",
    "\n",
    "Simplemente se define un objeto de modelo Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmfogzmn9kqv"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNzLOAK5Y-mR"
   },
   "source": [
    "### Añadir la primera capa totalmente conectada (capa Densa)\n",
    "\n",
    "Hyper-parametros de la capa:\n",
    "- número de unidades/neuronas: 512\n",
    "- función de activación: ReLU (rompiendo relacion lineal)\n",
    "- input_shape: (784, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBsfDyGE-FX5"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=512, activation='relu', input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vwqx1wZUa1rH"
   },
   "source": [
    "### Añadir una capa de Dropout \n",
    "\n",
    "Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAmpLPlr-pOX"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBsfDyGE-FX5"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAmpLPlr-pOX"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBsfDyGE-FX5"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBsfDyGE-FX5"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBsfDyGE-FX5"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=64, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGqvyDvNbzwN"
   },
   "source": [
    "### Añadir la segunda capa (capa de salida)\n",
    "\n",
    "- unidades: número de clases (10 en el caso del Fashion MNIST)\n",
    "- función de activación: 'softmax' (probabilidades de cada clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmkUuF9Y-3mG"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rRsMjsvcOua"
   },
   "source": [
    "### Compilar el modelo\n",
    "\n",
    "- Optimizer: Adam\n",
    "- Loss: Sparse softmax (categorical) crossentropy / accuracy en problemas binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbW3xeRK_CrN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1564588582610,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "8dQOL_EtChrN",
    "outputId": "a839ebcc-3021-4b90-9598-3e4746c339fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 591562 (2.26 MB)\n",
      "Trainable params: 591562 (2.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9kxIIFU1cany"
   },
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26920,
     "status": "ok",
     "timestamp": 1564588612289,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "s-_oLiE0_3A2",
    "outputId": "71872c57-618f-42c1-ab22-2bedc29abcc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1875/1875 [==============================] - 16s 7ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.7920\n",
      "Epoch 2/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8435\n",
      "Epoch 3/80\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8535\n",
      "Epoch 4/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8627\n",
      "Epoch 5/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8681\n",
      "Epoch 6/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3493 - sparse_categorical_accuracy: 0.8720\n",
      "Epoch 7/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3419 - sparse_categorical_accuracy: 0.8756\n",
      "Epoch 8/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3304 - sparse_categorical_accuracy: 0.8804\n",
      "Epoch 9/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3212 - sparse_categorical_accuracy: 0.8829\n",
      "Epoch 10/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.8862\n",
      "Epoch 11/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3086 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 12/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3068 - sparse_categorical_accuracy: 0.8872\n",
      "Epoch 13/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8918\n",
      "Epoch 14/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2978 - sparse_categorical_accuracy: 0.8905\n",
      "Epoch 15/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 16/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2854 - sparse_categorical_accuracy: 0.8953\n",
      "Epoch 17/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2857 - sparse_categorical_accuracy: 0.8961\n",
      "Epoch 18/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2794 - sparse_categorical_accuracy: 0.8968\n",
      "Epoch 19/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2755 - sparse_categorical_accuracy: 0.8978\n",
      "Epoch 20/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2713 - sparse_categorical_accuracy: 0.9016\n",
      "Epoch 21/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2710 - sparse_categorical_accuracy: 0.9001\n",
      "Epoch 22/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2642 - sparse_categorical_accuracy: 0.9035\n",
      "Epoch 23/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2624 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 24/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2642 - sparse_categorical_accuracy: 0.9037\n",
      "Epoch 25/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2584 - sparse_categorical_accuracy: 0.9047\n",
      "Epoch 26/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2548 - sparse_categorical_accuracy: 0.9066\n",
      "Epoch 27/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2531 - sparse_categorical_accuracy: 0.9069\n",
      "Epoch 28/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2548 - sparse_categorical_accuracy: 0.9070\n",
      "Epoch 29/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2491 - sparse_categorical_accuracy: 0.9079\n",
      "Epoch 30/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2453 - sparse_categorical_accuracy: 0.9089\n",
      "Epoch 31/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2497 - sparse_categorical_accuracy: 0.9092\n",
      "Epoch 32/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2429 - sparse_categorical_accuracy: 0.9107\n",
      "Epoch 33/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2403 - sparse_categorical_accuracy: 0.9118\n",
      "Epoch 34/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2412 - sparse_categorical_accuracy: 0.9131\n",
      "Epoch 35/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2358 - sparse_categorical_accuracy: 0.9123\n",
      "Epoch 36/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9130\n",
      "Epoch 37/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2356 - sparse_categorical_accuracy: 0.9132\n",
      "Epoch 38/80\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2331 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 39/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9161\n",
      "Epoch 40/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2260 - sparse_categorical_accuracy: 0.9170\n",
      "Epoch 41/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9160\n",
      "Epoch 42/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2278 - sparse_categorical_accuracy: 0.9179\n",
      "Epoch 43/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2246 - sparse_categorical_accuracy: 0.9179\n",
      "Epoch 44/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2201 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 45/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9183\n",
      "Epoch 46/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2190 - sparse_categorical_accuracy: 0.9197\n",
      "Epoch 47/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9210\n",
      "Epoch 48/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2197 - sparse_categorical_accuracy: 0.9211\n",
      "Epoch 49/80\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9213\n",
      "Epoch 50/80\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9216\n",
      "Epoch 51/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9222\n",
      "Epoch 52/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2086 - sparse_categorical_accuracy: 0.9235\n",
      "Epoch 53/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2064 - sparse_categorical_accuracy: 0.9247\n",
      "Epoch 54/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 55/80\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9232\n",
      "Epoch 56/80\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9247\n",
      "Epoch 57/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2054 - sparse_categorical_accuracy: 0.9245\n",
      "Epoch 58/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9259\n",
      "Epoch 59/80\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9248\n",
      "Epoch 60/80\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2009 - sparse_categorical_accuracy: 0.9269\n",
      "Epoch 61/80\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2036 - sparse_categorical_accuracy: 0.9258\n",
      "Epoch 62/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2030 - sparse_categorical_accuracy: 0.9263\n",
      "Epoch 63/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2008 - sparse_categorical_accuracy: 0.9265\n",
      "Epoch 64/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2005 - sparse_categorical_accuracy: 0.9266\n",
      "Epoch 65/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2016 - sparse_categorical_accuracy: 0.9272\n",
      "Epoch 66/80\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1941 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9272\n",
      "Epoch 68/80\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1917 - sparse_categorical_accuracy: 0.9308\n",
      "Epoch 69/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1896 - sparse_categorical_accuracy: 0.9305\n",
      "Epoch 70/80\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9314\n",
      "Epoch 71/80\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9304\n",
      "Epoch 72/80\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9306\n",
      "Epoch 73/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1924 - sparse_categorical_accuracy: 0.9299\n",
      "Epoch 74/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 75/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 76/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9320\n",
      "Epoch 77/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9313\n",
      "Epoch 78/80\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 79/80\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9352\n",
      "Epoch 80/80\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cb72b12310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mj23nxmtcrhd"
   },
   "source": [
    "### Evaluación del modelo y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1564588614802,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "-nQCioOmAL7i",
    "outputId": "4e4abac6-7e3b-49db-b9bf-7fcf3267fd2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3359 - sparse_categorical_accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1564588618623,
     "user": {
      "displayName": "Juan Gabriel Gomila Salas",
      "photoUrl": "https://lh4.googleusercontent.com/-RJ38mzk8Fog/AAAAAAAAAAI/AAAAAAAAA_g/VV8PcNMAUrk/s64/photo.jpg",
      "userId": "03106941341701838274"
     },
     "user_tz": -120
    },
    "id": "Ozv2YVlxcx1h",
    "outputId": "5ec94881-fd81-4779-ad24-a1b3664ba96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9031999707221985\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Noi53-uq9yhl"
   },
   "source": [
    "## Paso 5 : Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo_cnn_FASHION.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab 3 - Crear una Red Neuronal Artificial en TensorFlow 2.0.ipynb",
   "provenance": [
    {
     "file_id": "1tj02zPuUkkbLob1oo63f9TliYj5DQHA3",
     "timestamp": 1564587360109
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
